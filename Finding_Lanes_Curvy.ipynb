{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Finding Lane Lines in Video** \n",
    "***\n",
    "This is a project using the teaser info that I learned before the actual course was released.\n",
    "In this notebook I am working on the test clip to try extracting the lanes. This clip is specifically more dificult than wat I've seen until now in the course because:\n",
    "- I have to read in a movie clip, the course showed only images  \n",
    "- The lanes in this clip are specifically bendy, meaning the car is not driving in a strait line\n",
    "\n",
    "Never the less this small project uses all the functions learn for image editing. The video that will be used is 'test.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing relevant packages for data manipulation\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing relevant packages for computer vision\n",
    "import cv2\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating editing functions\n",
    "def grayscale(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "def gaussian_blur(img, kernel_size):\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    # initializing a blank mask\n",
    "    mask = np.zeros_like(img)\n",
    "    \n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 13], thickness=8):\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            if y2!=y1:\n",
    "                slope = float(x2-x1)/(y2-y1)\n",
    "                y_t = 0\n",
    "                if slope < 0: # left lane, negative slope\n",
    "                    xMIN = slope*(img.shape[0]-1-y1) + x1\n",
    "                    xMAX = slope*(330-y1) + x1\n",
    "                    y_t=330\n",
    "                elif slope > 0: # right lane, positive slope\n",
    "                    xMIN = slope*(img.shape[0]-1-y1) + x1\n",
    "                    xMAX = slope*(360-y1) + x1\n",
    "                    y_t = 360\n",
    "                cv2.line(img, (int(xMIN),img.shape[0]-1),(int(xMAX),y_t), color, thickness)\n",
    "    \n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((*img.shape, 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "    \n",
    "def weighted_img(init_img, line_img, alpha=0.8, beta=1.0, gamma=0.0):\n",
    "    return cv2.addWeighted(init_img, alpha, line_img, beta, gamma)\n",
    "\n",
    "def draw_lines2(img, lines, color=[255, 0, 0], thickness=3):\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "def hough_lines2(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((*img.shape, 3), dtype=np.uint8)\n",
    "    draw_lines2(line_img, lines)\n",
    "    return line_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a pipeline for frame editing\n",
    "def process_video(img):\n",
    "    gray = grayscale(img)\n",
    "    \n",
    "    kernel_size = 5\n",
    "    blur_gray = gaussian_blur(gray, kernel_size)\n",
    "    \n",
    "    low_threshold = 50\n",
    "    high_threshold = 150\n",
    "    edges = canny(blur_gray, low_threshold, high_threshold)\n",
    "    \n",
    "    imgsh = img.shape\n",
    "    vertices = np.array([[(200,imgsh[0]-55),(660,430),(675,430),(imgsh[1]-175,imgsh[0]-55)]], dtype=np.int32)\n",
    "    masked_edges = region_of_interest(edges, vertices)\n",
    "    \n",
    "    rho = 1 # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi/180 # angular resolution in radians of the Hough grid\n",
    "    threshold = 10 # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_len = 10\n",
    "    max_gap = 20\n",
    "    line_img = hough_lines2(masked_edges, rho, theta, threshold, min_len, max_gap)\n",
    "    \n",
    "    result = weighted_img(img, line_img, 0.8, 1.2, 0)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video curvy_out.mp4\n",
      "[MoviePy] Writing video curvy_out.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 251/251 [00:10<00:00, 23.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: curvy_out.mp4 \n",
      "\n",
      "Wall time: 12 s\n"
     ]
    }
   ],
   "source": [
    "# Applying the pipeline on the clip, frame by frame\n",
    "file_output = 'curvy_out.mp4'\n",
    "clip1 = VideoFileClip('curvy.mp4')\n",
    "file_clip = clip1.fl_image(process_video)\n",
    "%time file_clip.write_videofile(file_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cv2.addWeighted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
